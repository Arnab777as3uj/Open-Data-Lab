# Introduction to Spark

## Details
### Instructor: Pete Alonzi (LPA2A@VIRGINIA.EDU)
### Dates: Jan 16,23,28,30: 12:00-12:50 EST
### Location: Dell 1, Room 105
### Spark is a popular tool for managing data at scale

## Outline
* Jan 16: Setting up your spark environment and storing data and Exercise Description (Exercise released)
  * [setup spark](https://github.com/UVA-DSI/Open-Data-Lab/blob/master/education/Spark19SpDS6003-001/setup.ipynb)
  * [store data for processing](https://github.com/UVA-DSI/Open-Data-Lab/blob/master/education/Spark19SpDS6003-001/data_storage.ipynb)
  * [exercise details](https://github.com/UVA-DSI/Open-Data-Lab/blob/master/education/Spark19SpDS6003-001/exercise_submissions/README.md)
* Jan 23: Understanding Data Frames (they are different from Python/R) 
* Jan 28: ML pipelining in Spark - Visualization if time
* Jan 30: Workshop Day - short presentations and group work (Exercise due)

## Assignments
There is one assignment for this series. It is a practical implementation of the techniques learned in class. The assignment is due on Jan 30 at 0900 (aka 9am). Submission details are [here](https://github.com/UVA-DSI/Open-Data-Lab/blob/master/education/Spark%2019Sp%20DS%206003-001/exercise_submissions/README.md). 

## Resources
* [UVA Library Spark Workshop](https://github.com/alonzi/spark-intro)
* [DSI Practice class spark resources 2018](https://github.com/alonzi/spark)
* [Spark Python API Docs](https://spark.apache.org/docs/latest/api/python/index.html#)
* [Apache Parquet Docs](https://parquet.apache.org/)
* [More Accessible Parquet Info](https://spoddutur.github.io/spark-notes/deep_dive_into_storage_formats.html)
* [Bonus: Twitter Example - Not in scope of this workshop](https://www.toptal.com/apache/apache-spark-streaming-twitter?!)
### From Databricks
* [Databricks resources](https://docs.databricks.com/index.html)
* [Matplotlib and ggplot example](https://docs.databricks.com/user-guide/visualizations/matplotlib-and-ggplot.html?1)
### Further Reading about Amazon EMR - Elastic MapReduce
* [Using Apache Spark with Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/apache-spark.html)
* [Build Amazon SageMaker notebooks backed by Spark in Amazon EMR](https://aws.amazon.com/blogs/machine-learning/build-amazon-sagemaker-notebooks-backed-by-spark-in-amazon-emr/)

## S3 bucket
* odl-spark19spds6003-001

## Jupyter Server Link
* https://open-data-lab.signin.aws.amazon.com/console (IAM use name is your UVA id)

## Dataset example
* https://www.kaggle.com/city-of-seattle/seattle-checkouts-by-title 
